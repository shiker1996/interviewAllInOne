# 知识点梳理

## 数据库

### 主从复制

- 原理

    - 原文

        - 1)、Slave 上面的 IO_thread 连接上 Master，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容；
          2)、Master 接收到来自 Slave 的 IO_thread 的请求后，通过负责复制的 IO 进程根据请求信息读取指定日志指定位置之后的日志信息，返回给 Slave 的 IO_thread。返回信息中除了日志所包含的信息之外，还包括本次返回的信息已经Master 端的 bin-log file 的以及bin-log pos；
          3)、Slave 的 IO_thread 接收到信息后，将接收到的日志内容依次添加到 Slave 端的relay-log 文件的最末端，并将读取到的 Master 端的 bin-log 的文件名和位置记录到master-info 文件中，以便在下一次读取的时候能够清楚的告诉 Master“我需要从某个bin-log 的哪个位置开始往后的日志内容，请发给我”；
          4)、Slave 的 Sql_thread 检测到 relay-log 中新增加了内容后，会马上解析 relay-log的内容成为在 Master 端真实执行时候的那些可执行的内容，并在本数据库中执行。

    - 我的理解

        - 从库的IO线程负责读取并保存到relay-log
        - 主库的进程返回对应上次同步时间之后的bin-log信息
        - 从库的sql线程监听relay-log变动并在从库执行
        - 原理示意：

- 主从延迟

    - 处理方法

        - 读从库的sql语句导致

            - 增加多个从库

                - 使用多台slave来分摊读请求，再从这些slave中取一台专用的服务器，只作为备份用，不进行其他任何操作，就能相对最大限度地达到'实时'的要求了

            - 加入缓存

                - 写入时写到缓存中，缓存失效再读从库

        - 主库TPS并发太高

            - 加入同步中间件
            - 降低并发量

                - 分库分表，大表迁移至hbase。接口异步，程序和脚本跑批使用限流和限速来控制并发量

    - 产生原理

        - 一句话概括

            - 从库的sql执行顺序是随机的，而且从库sql执行为单线程。导致sql争抢锁，和锁等待

        - 原文

            - 谈到MySQL数据库主从同步延迟原理，得从mysql的数据库主从复制原理说起，mysql的主从复制都是单线程的操作，主库对所有DDL和 DML产生binlog，binlog是顺序写，所以效率很高，slave的Slave_IO_Running线程到主库取日志，效率很比较高，下一步， 问题来了，slave的Slave_SQL_Running线程将主库的DDL和DML操作在slave实施。DML和DDL的IO操作是随即的，不是顺 序的，成本高很多，还可能可slave上的其他查询产生lock争用，由于Slave_SQL_Running也是单线程的，所以一个DDL卡主了，需要 执行10分钟，那么所有之后的DDL会等待这个DDL执行完才会继续执行，这就导致了延时。有朋友会问：“主库上那个相同的DDL也需要执行10分，为什 么slave会延时？”，答案是master可以并发，Slave_SQL_Running线程却不可以。

    - 产生原因

        - 当主库的TPS并发较高时，产生的DDL数量超过slave一个sql线程所能承受的范围，那么延时就产生了，当然还有就是可能与slave的大型query语句产生了锁等待。

### 事务

- 事务的基本要素ACID

    - 原子性：要么全部完成，要么全部不完成
    - 一致性：数据库的完整性约束没有破坏
    - 隔离性：防止多个事务交叉执行而导致数据不一致
    - 永久性：数据修改是永久的

- 事务的隔离级别

    - 隔离级别

        - 读未提交

            - 读取最新版本的数据记录

        - 读已提交

            - 写数据时会添加行级锁

                - 防止脏读
                - 可能会不可重复读和幻读

            - 每次读取数据前都生成一个ReadView

        - 可重复读

            - 如果检索条件有索引，默认加锁方式为next-key锁；如果检索条件没有索引，更新数据时会锁住整张表

                - 防止脏读和不可重复读
                - 可能会幻读

                    - 使用间隙锁防止幻读发生

            - 默认隔离级别
            - 在第一次读取数据时生成一个ReadView，不会更新

        - 串行化

            - 锁表

                - 不会出现并发问题

    - 并发问题

        - 脏读

            - 事务A读取了事务B更新的数据，B回滚后导致A读的是脏数据

        - 不可重复读

            - 事故B在事务A多次读取的过程中更新数据，导致A读取同一数据不一致
            - 侧重于单条数据修改产生的并发问题
            - 需要锁行

        - 幻读

            - 事故B在事务A多次读取的过程中插入或删除数据，导致A检索同一条件下的结果不一致
            - 侧重于插入或者删除数据后产生的并发问题
            - 需要锁表，mysql通过间隙锁解决

- 多版本并发控制

    - 版本链

        - trx_id

            - 用于保存每次对该记录进行修改的事务的id

        - roll_pointer

            - 存储一个指针，指向这条数据记录上一个版本的地址，可以通过它获取到该记录上一个版本的数据信息

    - ReadView

        - 存储着系统中当前活跃着的读写事务，即begin了但还未commit的事务,把这个列表命名为为m_ids
        - 判断某条记录版本是否对当前查询可见

            - 如果被访问版本的trx_id属性值小于m_ids列表中最小的事务id，表明生成该版本的事务在生成ReadView前已经提交，所以该版本可以被当前事务访问
            - 如果被访问版本的trx_id属性值大于m_ids列表中最大的事务id，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问
            - 如果被访问版本的trx_id属性值在m_ids列表中最大的事务id和最小事务id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。
            - 如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本，如果最后一个版本也不可见的话，那么就意味着该条记录对该事务不可见，查询结果就不包含该记录

    - 读已提交和可重复读的区别

- 锁与死锁

    - 死锁

        - 产生

            - 两个事务或多个事务在同一资源上相互占用，并请求对方锁定的资源
            - 多个事务以不同顺序锁定资源

                - 有的引擎会死锁，有的不会死锁

            - 多个事务锁定同一资源

                - 真正的数据冲突

        - 处理方式

            - 部分或者完全回滚其中一个事务
            - InnoDB处理方法：将持有最少行级排他锁的事务进行回滚

    - 表锁

        - 读读不阻塞，读写阻塞，写写阻塞
        - 开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低
        - 尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁

    - 行锁（Record Lock）

        - 锁直接加在索引记录上面，锁住的是key

            - 普通索引为行锁，唯一索引或主键为记录锁
            - 只出现在可重复读事务中

        - 开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高
        - insert，delete，update在事务中都会自动默认加上排它锁。
        - 在一条select语句后加上for update，则查询到的数据会被加上一条排它锁，其它事务可以读取，但不能进行更新和插入操作
        - 行锁必须有索引且索引有效才能实现，否则会自动锁全表，那么就不是行锁了
        - 尽量控制事务大小，减少锁定资源量和时间长度

    - 间隙锁（Gap Lock）

        - 查询条件命中非唯一索引，并且没有查询到符合条件的记录
        - 锁定索引记录间隙，确保索引记录的间隙不变。间隙锁是针对事务隔离级别为可重复读或以上级别而已的
        - 合理设计索引，尽量缩小锁的范围
        - 尽可能减少索引条件，避免间隙锁

    - 临间锁（Next-Key Lock）

        - 查询条件命中非唯一索引，不过有匹配到数据库记录

###  innodb myisam 区别

- InnoDB是事务型引擎，MyISAM是非事务引擎
- InnoDB支持外键，MyISAM不支持
-  InnoDB是聚集索引，索引和数据文件是绑定在一起的，通过主键索引查询效率很高，辅助索引要查询两次；而MyISAM是非聚集性索引，索引和数据文件分离，主键索引和辅助索引独立

    - MyISAM
    - InnoDB

- InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快（注意不能加有任何WHERE条件）
- InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快（注意不能加有任何WHERE条件）
- Innodb不支持全文索引，而MyISAM支持全文索引，在涉及全文索引领域的查询效率上MyISAM速度更快高；PS：5.7以后的InnoDB支持全文索引了
- MyISAM表格可以被压缩后进行查询操作
-  InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁
- InnoDB表必须有唯一索引（如主键）（用户没有指定的话会自己找/生产一个隐藏列Row_id来充当默认主键），而Myisam可以没有
- Innodb存储文件有表定义文件数据文件。MyISAM存储文件有表定义文件数据文件和索引文件

### 索引

- Btree索引

    - 适用于全键值，键值范围或键前缀查找，键前缀查找只适用于最左前缀的查找
    - 全值匹配：指的是和索引中的所有列进行匹配
    - 匹配最左前缀：在复合索引中从最左列使用索引，会对索引树进行二分查找（例如查找语文60分，数学62分的同学，组合索引定位如下：）

- 哈希索引

    - 精准匹配所有列才生效，也不能排序

- B树

    - M阶B树

        - 性质

            - 一个节点最多拥有M个子节点，一个节点的元素个数为x，子节点个数为y
            - 子节点个数=x+1
            - 根节点元素个数：1<=x<=M-1，2<=y<=M
            - 非根节点个数：ceil(M/2-1)<=x<=M-1, ceil(M/2)<=y<=M

        - 插入原则

            - 每次从叶子节点插入，达到m-1时，中间元素向上分裂

        - B树查找5-8:（6.8->5->6.8->7->6.8->9.10）

    - B+树

        - N叉B+树最多含有N个元素，而B树最多含有n-1个元素
        - B+树的叶子节点包存所有的元素信息，按元素大小顺序排列
        - 所有非叶子节点地可以看作是元素的一部分
        - 相比b树，所有查询都要走到叶子节点，查询效率更稳定，范围查找时，避免了回旋查找
        - B+树查找5-8：(5->7->6->5.6.7.8.9.10)

###  mysql 优化（explain）

- id

    - SELECT查询序列号

- select_type

    - select语句的类型（简单查询，主查询，UNION连接查询，子查询等）

- table

    - 查询的表

- type

    - 表的连接类型

        - system-仅有一行的系统表
        - const-单表的主键查询和唯一索引查询
        - eq_ref-关联表使用主键或唯一索引连接
        - index-索引查询
        - range-范围查询
        - ref-关联表使用非唯一索引连接
        - all-全表查询

- possible_keys

    - 指出能使用哪个索引在表中找到行

- key

    - 实际查询用到的索引

- key_length

    - 实际使用了一个组合索引中的几个字段

- ref

    - 使用了哪个列或常数与索引一起来查询记录

- rows

    - 查询时必须检查的行数

### 分库分表

- 为什么使用2的n次幂进行分表？

    - 可以保证每次扩容奇数表重分到奇数表，避免大批量数据迁移

- 使用雪花算法生成全局ID时如何保证机器号不重叠？

    - 对机器进行心跳检测，及时回收长时间下线机器的机器号

- 如何做分页查询？

    - 接入ES

- 分表中间件shadingsphere的坑

    - 3.0在服务启动会强制扫描表结构，确认分表字段是否一致，导致sql执行与项目上线不能并发执行
    - 3.1版本在分库分表的数据库中，查询单表的数据会导致shardjing-sphere的路由失败

## 基础

### 操作系统

- 进程和线程的区别

    - 进程

        - 进程间通讯方式

            - 共享存储：读写互斥

                - 基于数据结构的共享
                - 基于存储区的共享

            - 消息传递

                - 直接通信

                    - 消息直接挂到接受进程的消息缓冲队列

                - 间接通信

                    - 消息要先发送到中间实体中

            - 管道通信

                - 半双工（单向）通信

        - 程序段、数据段、进程控制块三部分组成了进程实体

            - 进程控制块PCB

                - 进程描述信息
                - 进程控制和管理信息
                - 资源分配清单
                - 处理机相关信息

            - 程序段

                - 存放要执行的代码

            - 数据段

                - 存放程序运行过程中处理的各种数据

    - 线程

        - 线程是处理机调度的单位
        - 线程有线程ID、线程控制块

    - 线程和进程一样分为五个阶段：创建、就绪、运行、阻塞、终止
    - 进程是资源分配的最小单位，线城是CPU调度的最小单位
    - 进程和线程之间都可以并发执行
    - 进程是拥有系统资源的一个独立单位，线程不拥有系统资源，但可以访问进程的资源
    - 创建和销毁进程的开销要大于创建或撤销线程的开销

- 死锁和解决方式

    - 产生方式

        - 竞争资源
        - 进程间推进顺序非法

    - 必要条件

        - 互斥条件、请求和保持条件、不剥夺条件、环路等待条件

    - 解决方法

        - 预防死锁

            - 破坏死锁产生的必要条件

                - 规定进程一次性访问整个运行过程中的所有资源
                - 规定进程当有新的资源请求不能满足时，必须释放当前进程已经占有的资源再重新申请
                - 按所有资源类型进行线性排队，并赋予不同的序号

        - 避免死锁

            - 银行家算法

        - 检测和解决死锁

            - 检测：使用资源分配图和死锁定理
            - 解决：剥夺资源和撤销进程

- 两种CPU状态

    - 用户态和内核态

        - 三种切换方式

            - 用户态->内核态

                - 系统调用

                    - 用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作

                - 异常
                - 外围设备中断

            - 内核态->用户态

                - 设置程序状态字PSW

        - 内核态

            - 运行操作系统程序，操作硬件

        - 用户态

            - 运行用户程序

        - 区别

            - 处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的；处于内核态执行时，则能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占的。
            - 运行在用户态下的程序不能直接访问操作系统内核数据结构和程序

### 并发

- 线程创建方式

    - 继承Thread类创建线程
    - 实现Runnable接口创建线程

        - 使用线程池例如用Executor框架
        - 使用Callable和Future创建线程

- 线程池7大参数

    - corePoolSize 线程池核心线程大小

        - 线程池中会维护一个最小的线程数量，即使这些线程处理空闲状态，他们也不会被销毁，除非设置了allowCoreThreadTimeOut。这里的最小线程数量即是corePoolSize
        - 线程数 = CPU核心数 *(1+平均等待时间/平均工作时间)

    - maximumPoolSize 线程池最大线程数量

        - 池中允许的最大线程数。需要注意的是当核心线程满且阻塞队列也满时才会判断当前线程数是否小于最大线程数，并决定是否创建新线程

    - keepAliveTime 空闲线程存活时间

        - 一个线程如果处于空闲状态，并且当前的线程数量大于corePoolSize，那么在指定时间后，这个空闲线程会被销毁，这里的指定时间由keepAliveTime来设定

    - unit 空闲线程存活时间单位

        - keepAliveTime的计量单位

    - workQueue 工作队列

        - 无界队列

            - LinkedBlockingQuene

                - 基于链表的无界阻塞队列

            - PriorityBlockingQueue

                - 具有优先级的无界阻塞队列

            - 当任务耗时较长时可能会导致大量新任务在队列中堆积最终导致OOM

        - 有界队列

            - ArrayBlockingQueue

                - 基于数组的有界阻塞队列

            - 线程池较小有界队列较大时可减少内存消耗，降低cpu使用率和上下文切换，但是可能会限制系统吞吐量

        - 阻塞（同步移交）队列

            - SynchronousQuene

                - 不缓存任务的阻塞队列

            - 只有在使用无界线程池或者有饱和策略时才建议使用该队列

    - threadFactory 线程工厂
    - handler 拒绝策略

        - CallerRunsPolicy

            - 在调用者线程中直接执行被拒绝任务的run方法

        - AbortPolicy

            - 直接丢弃任务，并抛出RejectedExecutionException异常

        - DiscardPolicy

            - 直接丢弃任务，什么都不做。

        - DiscardOldestPolicy

            - 先将阻塞队列中的头元素出队抛弃，再尝试提交任务。
            - 如果此时阻塞队列使用PriorityBlockingQueue优先级队列，将会导致优先级最高的任务被抛弃，因此不建议将该种策略配合优先级队列使用

- 自带线程池问题

    - 使用无界队列的线程池

        - FixedThreadPool
        - SingleThreadExecutor
        - 当任务处理速度比较慢的时候,虽然新增任务越来越多,队列中堆积的任务就越来越多,最终会占用大量内存,并发生OOM,就会严重影响到程序运行

    - 使用阻塞队列的线程池

        - CachedThreadPool

            - 最大线程数为2^31-1,任务特别多的时候,就会创建非常多的线程,进而导致系统内存不足

    - 使用延迟队列的线程池

        - ScheduledThreadPool
        - SingleThreadScheduledExector
        - 同样是无界队列，会产生OOM

- 线程安全

    - 乐观锁

        - 假设数据一般情况不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果冲突，则返回给用户异常信息，让用户决定如何去做
        - cas实现

            - 比较并交换

                - 三个操作数

                    - 内存位置（V）、预期原值（A）和新值(B)

                - 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该 位置的值。

            - CAS存在的问题

                - ABA问题

                    - 如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。
                    - ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。

                - 循环时间长开销大
                - 只能保证一个共享变量的原子操作

                    - AtomicReference

        - 版本号控制

            - 在数据表中加上一个数据版本号 version 字段，表示数据被修改的次数。当数据被修改时，version 值会 +1。当线程 A 要更新数据时，在读取数据的同时也会读取 version 值，在提交更新时，若刚才读取到的 version 值与当前数据库中的 version 值相等时才更新，否则重试更新操作，直到更新成功

    - AbstractQueuedSynchronizer-抽象队列同步器

        - volatile int state

            - 代表共享资源

        - FIFO线程等待队列

            - 多线程争用资源被阻塞时会进入此队列
            - 节点NODE

                - 对每一个等待获取资源的线程的封装，其包含了需要同步的线程本身及其等待状态，如是否被阻塞、是否等待唤醒、是否已经被取消等

        - 两种工作方式

            - 独占方式

                - 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的

            - 共享方式

                - 以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作

        - AQS中的等待队列和同步队列

            - 原理图：

    - reentrantLock 底层实现

        - 每一个ReentrantLock自身维护一个AQS队列记录申请锁的线程信息；
        - 通过大量CAS保证多个线程竞争锁的时候的并发安全；
        - 可重入的功能是通过维护state变量来记录重入次数实现的。
        - 公平锁需要维护队列，通过AQS队列的先后顺序获取锁，缺点是会造成大量线程上下文切换
        - 非公平锁可以直接抢占，所以效率更高

    - synchronize

        - 原子性：synchronized保证语句块内操作是原子的
        - 可见性：synchronized保证可见性
        - 有序性：synchronized保证有序性
        - 原理

            - 代码块的同步是利用monitorenter和monitorexit这两个字节码指令。它们分别位于同步代码块的开始和结束位置。当jvm执行到monitorenter指令时，当前线程试图获取monitor对象的所有权，如果未加锁或者已经被当前线程所持有，就把锁的计数器+1；当执行monitorexit指令时，锁计数器-1；当锁计数器为0时，该锁就被释放了
            - 方法级的同步是隐式。JVM可以从方法常量池中的方法表结构中的 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法。当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor
            - 重量级锁

                - 有实际竞争，且锁竞争时间长。

        -  锁优化（锁自旋，自适应锁自旋、锁消除，锁粗化）

            - 偏向锁

                - 无实际竞争，且将来只有第一个申请锁的线程会使用锁。
                - 减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗
                - 偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），因此，只需要在Mark Word中CAS记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁

            - 轻量级锁

                - 无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。
                - 减少无实际竞争情况下，使用重量级锁产生的性能消耗
                - 轻量级锁是相对于重量级锁而言的。使用轻量级锁时，不需要申请互斥量，仅仅将Mark Word中的部分字节CAS更新指向线程栈中的Lock Record（Lock Record：JVM检测到当前对象是无锁状态，则会在当前线程的栈帧中创建一个名为LOCKRECOD表空间用于copy Mark word 中的数据），如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁

            - 锁自旋

                - 就是自旋的次数是通过JVM在运行时收集的统计信息，动态调整自旋锁的自旋次数上界。

            - 锁粗化

                - 将多次连接在一起的加锁、解锁操作合并为一次，将多个连续的锁扩展成一个范围更大的锁

            - 锁消除

                - 锁消除即删除不必要的加锁操作。根据代码逃逸技术，如果判断到一段代码中，堆上的数据不会逃逸出当前线程，那么可以认为这段代码是线程安全的，不必要加锁

    - java内存模型

        -  定义了线程和主内存之间的抽象关系，定义了 JVM 在计算机内存(RAM)中的工作方式
        - 线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本

            - 主内存、工作内存与 Java 内存区域中的 Java 堆、栈、方法区等并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起来，那从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分区域。

        - 指令重排序

            - 编译器优化重排序

                - 编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序

            - 指令级并行的重排序

                - 如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序

            - 内存系统的重排序

                - 处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行

        - 内存屏障

            - 通过内存屏障可以禁止特定类型处理器的重排序，从而让程序按我们预想的流程去执行
            - 是一个CPU指令

                - 保证特定操作的执行顺序
                - 影响某些数据（或则是某条指令的执行结果）的内存可见性
                - 插入一条内存屏障指令会告诉编译器和CPU：不管什么指令都不能和这条内存屏障指令重排序

            - volatile实现原理

                - 如果一个变量是volatile修饰的，JMM会在写入这个字段之后插进一个写屏障指令，并在读这个字段之前插入一个读屏障指令

                    - 一个线程写入变量a后，任何线程访问该变量都会拿到最新值
                    - 在写入变量a之前的写入操作，其更新的数据对于其他线程也是可见的。因为内存屏障指令会刷出缓存中的所有先前的写入

        - 先行发生原则

            - 程序顺序规则

                - 一个线程中的每个操作，happens-before于该线程中的任意后续操作

            - 监视器锁规则

                - 对一个锁的解锁，happens-before于随后对这个锁的加锁

            - volatile变量规则

                - 对一个volatile域的写，happens-before于任意后续对这个volatile域的读。

            - 传递性

                - 如果A happens-before B，且B happens-before C，那么A happens-before C。一个happens-before规则对应于一个或多个编译器和处理器重排序规则

        - as-if-serial语义

            - 不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。

### java

- 多态

    - 运行时多态

        - 在运行期根据实际类型确定方法执行版本的分派动作
        - 重写

    - 编译时多态

        - 所有依赖静态类型来定位方法执行版本的分派动作。静态分派发生在编译阶段，因此确定静态分派的动作实际上不是由虚拟机来执行的，而是由编译器来完成。
        - 重载

- 反射

    - 原理

        - Java在编译之后会生成一个class文件，反射通过字节码文件找到其类中的方法和属性等

    - 使用场景

        - JAVA反射机制是在运行状态中，

            - 对于任意一个类，都能够知道这个类的所有属性和方法；
            - 对于任意一个对象，都能够调用它的任意一个属性和方法；

- 快速失败

    - 在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。
    - 原理

        - 迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。
        - 集合在被遍历期间如果内容发生变化，就会改变modCount的值。
        - 每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。
        - 源码所在方法：checkForComodification

    - java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。

- 安全失败

    - 由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。
    - java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。

- map

    - hashmap

        - hashmap 死循环场景transfer代码（并发线程对一个线程rehash后的表进行二次rehash时会形成死链）

            - do {
              Entry<K,V> next = e.next; //老表遍历
              int i = indexFor(e.hash, newCapacity);
              e.next = newTable[i];//新表插入
              newTable[i] = e;//新表插入
              e = next;//老表遍历
              } while (e != null);
            - 线程二执行完成
            - 线程一被调度回来执行
            - 线程一接着工作
            - 环形链接出现

        - hashmap存储结构

    - concurrentHashMap

        - **1.7**

            - ReentrantLock+Segment+HashEntry

                - 通过把整个Map分为N个Segment，可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。(读操作不加锁，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。)

        - **1.8**

            - ReentrantLock+Segment+HashEntry

                - Node中value和next都用volatile修饰，保证并发的可见性

        - 严格来说读取操作不能保证反映最近的更新

    - hashtable

        - 无论key还是value都不能为null，线程安全
        - 线程安全的方式是在修改数据时锁住整个HashTable

- object

    - 基本方法

        - hashcode

            - 用于哈希查找.返回该对象的哈希码值，是为了提高哈希表的性能

        - finalize

            - 对象在被GC释放之前一定会调用finalize方法，对象被释放前最后的挣扎,因为无法确定该方法什么时候被调用，很少使用

        - toString

            - 返回一个String字符串,用于描述当前对象的信息,可以重写返回对自己有用的信息，默认返回的是当前对象的类名+hashCode的16进制数字

        - equals

            - 判断两个对象是否相等

        - getClass

            - 获取运行时类型,返回值为Class对象

        - wait,notify,notifyAll

            - wait()用于让当前线程失去操作权限，当前线程进入等待序列
            - notify()用于随机通知一个持有对象的锁的线程获取操作权限
            - notifyAll()用于通知所有持有对象的锁的线程获取操作权限

    - 序列化

        - 把Java对象转换为字节序列的过程
        - 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中
        - 在网络上传送对象的字节序列
        - serialVersionUID

            - 希望类的不同版本对序列化兼容时，需要确保类的不同版本具有相同的serialVersionUID
            - 不希望类的不同版本对序列化兼容时，需要确保类的不同版本具有不同的serialVersionUID

## JVM

### 运行时数据区

- Java 内存区域和内存模型是不一样的东西，内存区域是指 Jvm 运行时将数据分区域存储，强调对内存空间的划分。

    - 内存模型（Java Memory Model，简称 JMM ）是定义了线程和主内存之间的抽象关系，即 JMM 定义了 JVM 在计算机内存(RAM)中的工作方式，如果我们要想深入了解Java并发编程，就要先理解好Java内存模型。

- 1.8之前内存区域图
- 1.8之后
- 程序计数器

    - 当前线程所执行的字节码的行号指示器。每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储

- 虚拟机栈

    - Java 方法执行的内存模型
    - 每个方法在执行的同时都会创建一个栈帧（Stack Frame，是方法运行时的基础数据结构）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。
    - 局部变量表

        - 存放方法参数和局部变量的区域

    - 操作栈

        - 初始状态为空的桶式结构栈。在方法执行过程中， 会有各种指令往栈中写入和提取信息
        - i++

            - 从局部变量表取出 i 并压入操作栈(load memory)，然后对局部变量表中的 i 自增 1(add&store memory)，将操作栈栈顶值取出使用，如此线程从操作栈读到的是自增之前的值

        - ++i

            - 先对局部变量表的 i 自增 1(load memory&add&store memory)，然后取出并压入操作栈(load memory)，再将操作栈栈顶值取出使用，线程从操作栈读到的是自增之后的值

    - 动态链接

        - 每个栈帧中包含一个在常量池中对当前方法的引用， 目的是支持方法调用过程的动态连接

    - 方法返回地址

- 本地方法栈

    - 为虚拟机使用到的 Native 方法服务

        - nativeheapOutOfMemory

- Java堆

    - 被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存
    - 堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”
    - 结构划分

        - 新生代

            - EDEN区
            - From Survivor区
            - To Survivor区

        - 老年代
        - 永久代

    - OutOfMemoryError

- 方法区

    - 各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据
    - JDK8 之前，Hotspot 中方法区的实现是永久代（Perm），JDK8 开始使用元空间（Metaspace），以前永久代所有内容的字符串常量移至堆内存，其他内容移至元空间，元空间直接在本地内存分配

        - 为什么要使用元空间取代永久代的实现

            - 字符串存在永久代中，容易出现性能问题和内存溢出。
            - 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。
            - 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。
            - 将 HotSpot 与 JRockit 合二为一

    - OutOfMemoryError

- 运行时常量池

    - 用于存放编译期生成的各种字面量和符号引用

### 堆内存分配策略

- 对象优先在Eden分配

    - 大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够的空间进行分配时，虚拟机发起一次 Minor GC
    - Eden区满后，对象复制到S0,清空Eden
    - 第二次eden满后，对象S0复制到S1，清空Eden和S0
    - 第三次eden满后，对象S1复制到S0，清空Eden和S1

- 长期存活的对象将进入老年代

    - 超过一定次数(默认15次，用-XX:MaxTenuringThreshold控制)未回收的，则进入老年代

- 大对象直接进入老年代

    - 很长的字符串以及数组。

- 动态对象年龄判定

    - 在Survivor空间中的相同年龄（多少次未回收）所有对象大小的总和大于Survivor空间的一半，那么那些年龄大于或者等于该年龄值得对象就可以直接进入老年代

- Minor GC的条件

    - 老年代最大可用的连续空间大于新生代所有对象总空间

        - Minor GC

    - 老年代最大可用的连续空间小于新生代所有对象总空间

        - HandlePromotionFailure允许担保失败

            - 老年代最大可用的连续空间大于历次晋升到老年代对象的平均大小

                - Minor GC

            - 老年代最大可用的连续空间小于历次晋升到老年代对象的平均大小

                - Full GC

        - HandlePromotionFailure不允许担保失败

            - Full GC

### 对象引用

- 引用判断

    - 引用计数法

        - 无法解决互相引用的场景

    - 可达性分析算法

        - 程序把所有的引用关系看作一张图，从一个节点GC ROOT开始，如果一个节点与GC ROOT之间没有引用链存在，则该节点视为垃圾回收的对象
        - GC Roots对象

            - 虚拟机栈(栈桢中的本地变量表)中的引用的对象
            - 方法区中的类静态属性引用的对象
            - 方法区中的常量引用的对象
            - 本地方法栈中JNI的引用的对象

- 引用分类

    - 强引用

        - Object obj = new Object()

    - 软引用

        - SoftReference<Object> sf = new SoftReference<Object>(obj);
        - 非必须引用，内存溢出之前进行回收，可以通过以下代码实现
        - 软引用主要用户实现类似缓存的功能，在内存足够的情况下直接通过软引用取值，无需从繁忙的真实来源查询数据，提升速度；当内存不足时，自动删除这部分缓存数据，从真正的来源查询这些数据。

    - 弱引用

        - WeakReference<Object> wf = new WeakReference<Object>(obj);
        - 弱引用是在第二次垃圾回收时回收，短时间内通过弱引用取对应的数据，可以取到，当执行过第二次垃圾回收时，将返回null
        - 弱引用主要用于监控对象是否已经被垃圾回收器标记为即将回收的垃圾，可以通过弱引用的isEnQueued方法返回对象是否被垃圾回收器

    - 虚引用

        - PhantomReference<Object> pf = new PhantomReference<Object>(obj);
        - 虚引用主要用于检测对象是否已经从内存中删除

### JVM加载过程

- 创建一个对象的步骤

    - 检测类是否被加载

        - 去常量池中查找这个类的符号引用。如果能找到符号引用，说明此类已经被加载到方法区（方法区存储虚拟机已经加载的类的信息），可以继续执行；如果找不到符号引用，就会使用类加载器执行类的加载过程，类加载完成后继续执行。

    - 为对象分配内存

        - 指针碰撞

            - 对于内存绝对规整的情况相对简单一些，虚拟机只需要在被占用的内存和可用空间之间移动指针即可

        - 空闲列表

            - 对于内存不规整的情况稍微复杂一点，这时候虚拟机需要维护一个列表，来记录哪些内存是可用的

    - 为分配的内存空间初始化零值

        - 对象的内存分配完成后，还需要将对象的内存空间都初始化为零值，这样能保证对象即使没有赋初值，也可以直接使用

    - 对对象进行其他设置

        - 在对象头中设置这个对象所属的类，类的元数据信息，对象的hashcode，GC分代年龄等信息

    - 执行 init 方法

        - 根据程序中的代码分配初始值

- 类加载过程

    - 加载

        - 将类的class文件读入到内存，并为之创建一个java.lang.Class对象
        - 通过使用不同的类加载器，可以从不同来源加载类的二进制数据

            - 从本地文件系统加载class文件，这是前面绝大部分示例程序的类加载方式
            - 从JAR包加载class文件，这种方式也是很常见的，前面介绍JDBC编程时用到的数据库驱动类就放在JAR文件中，JVM可以从JAR文件中直接加载该class文件
            - 通过网络加载class文件
            - 把一个Java源文件动态编译，并执行加载

    - 链接

        - 验证

            - 用于检验被加载的类是否有正确的内部结构，并和其他类协调一致
            - 文件格式验证

                - 验证字节流是否符合Class文件格式规范，并且能被当前的虚拟机加载处理

            - 元数据验证

                - 验证字节流是否符合Class文件格式规范，并且能被当前的虚拟机加载处理

            - 字节码验证

                - 主要的针对元数据验证后对方法体的验证。保证类方法在运行时不会有危害出现

            - 符号引用验证

                - 确定访问类型等涉及到引用的情况，主要是要保证引用一定会被访问到，不会出现类等无法访问的问题

        - 准备

            - 类准备阶段负责为类的静态变量分配内存，并设置默认初始值(0值)

        - 解析

            - 将类的二进制数据中的符号引用替换成直接引用

    - 初始化

        - 为类的静态变量赋予正确的初始值(代码值)

- 类加载器

    - JVM预定义加载器

        - 根类加载器bootstrap class loader

            - 用来加载 Java 的核心类

        - 扩展类加载器（extensions class loader）

            - 加载JRE的扩展目录

        - 应用程序类加载器（application class loader）

            - 加载来自Java命令的-classpath选项、java.class.path系统属性，或者CLASSPATH换将变量所指定的JAR包和类路径

        - 加载机制-双亲委派机制

            - 用户自己的类加载器，把加载请求传给父加载器，父加载器再传给其父加载器，一直到加载器树的顶层
            - 最顶层的类加载器首先针对其特定的位置加载，如果加载不到就转交给子类
            - 如果一直到底层的类加载都没有加载到，那么就会抛出异常ClassNotFoundException
            - 好处

                - 避免类的重复加载
                - 防止核心API库被随意篡改

    - 自定义加载器应用场景

        - tomcat的类加载器

            - 要解决的问题

                - 保证每个应用程序的类库是独立的，保证相互隔离
                - 同一个web容器中的相同类库相同版本可以共享
                - 容器的类库和程序的类库应该隔离
                - 支持jsp修改热加载

            - 自定义类加载器

                - commonLoader

                    - Tomcat最基本的类加载器

                        - 加载路径中的class可以被Tomcat容器本身以及各个Webapp访问

                - catalinaLoader

                    - Tomcat容器私有的类加载器

                        - 加载路径中的class对于Webapp不可见

                - sharedLoader

                    - Webapp共享的类加载器

                        - 加载路径中的class对于所有Webapp可见，但是对于Tomcat容器不可见

                - WebappClassLoader

                    - Webapp私有的类加载器

                        - 加载路径中的class只对当前Webapp可见

                - JasperLoader

                    - JSP文件所编译出来的那一个.Class文件

            - 加载机制

                - 先在本地缓存中查找是否已经加载过该类(对于一些已经加载了的类，会被缓存在resourceEntries这个数据结构中)，如果已经加载即返回，否则 继续下一步
                - 让系统类加载器(AppClassLoader)尝试加载该类，主要是为了防止一些基础类会被web中的类覆盖，如果加载到即返回，返回继续
                - 前两步均没加载到目标类，那么web应用的类加载器将自行加载，如果加载到则返回，否则继续下一步
                - 最后还是加载不到的话，则委托父类加载器(Common ClassLoader)去加载

            -  Common ClassLoader 想加载 WebApp ClassLoader 中的类，该怎么办？

                - 使用线程上下文加载器，可以让父类加载器请求子类加载器去完成类加载的动作

        - 热加载

            - spring boot devtools

                - 将业务代码单独通过一个自定义的加载器Custom Classloader来进行加载，当监控发现业务代码发生改变后，我们重新加载启动，老的业务代码的相关类则由虚拟机的垃圾回收机制来自动回收

        - 热部署

            - 将每个业务方通过一个classloader来加载。基于类的隔离机制，可以保障各个业务方的代码不会相互影响，同时也可以做到各个业务方进行独立的发布

        - 加密保护

            - 在打包的时候对class进行正向的加密操作，然后，在加载class文件之前通过自定义classloader先进行反向的解密操作，然后再按照标准的class文件标准进行加载，这样就完成了class文件正常的加载

- 类加载时机

    - 创建类的实例，也就是new一个对象
    - 访问某个类或接口的静态变量，或者对该静态变量赋值
    - 调用类的静态方法
    - 反射（Class.forName("com.lyj.load")）
    - 初始化一个类的子类（会首先初始化子类的父类）
    - JVM启动时标明的启动类，即文件名和类名相同的那个类

### 垃圾回收算法

- 标记-清除算法

    - 首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象
    - 标记和清除过程的效率都不高
    - 标记清除之后会产生大量不连续的内存碎片

- 复制算法

    - 将可用内存按容量划分为大小相等的两块，每次使用其中的一块。当这块的内存用完了，就将还存活着的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉
    - 实现简单，运行高效
    - 内存缩小为原来的一半，代价太高

- 标记-整理算法

    - 标记出所有需要回收的对象
    - 移动存活对象，同时更新存活对象中所有指向被移动对象的指针

- 分代收集算法

    - 把Java堆分为新生代和老年代

        - 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法
        - 老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收

### 垃圾收集器

- Serial收集器（用于新生代）

    - 单线程

        - 没有线程交互的开销，简单而高效
        - Client模式下的默认新生代收集器

- ParNew收集器（新生代）

    - 多线程

        - Server模式下的虚拟机中首选的新生代收集器

- Parallel Scavenge收集器（“吞吐量优先”收集器）（新生代）

    - 多线程

        - 吞吐量=运行用户代码时间 /（运行用户代码时间+垃圾收集时间）
        - 停顿时间越短对于需要与用户交互的程序来说越好，良好的响应速度能提升用户的体验
        - 高吞吐量可以最高效率地利用CPU时间，尽快地完成程序的运算任务，主要适合在后台运算而不太需要太多交互的任务

- Serial Old收集器（老年代）

    - 单线程

        - “标记-整理”算法

            - Client模式下的虚拟机使用

- Parallel Old收集器（老年代）

    - 多线程

        - “标记-整理”算法

            - 在注重吞吐量及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge+Parallel Old收集器

- CMS收集器（Concurrent Mark Sweep）

    - 多线程

        - “标记-清除”算法

            - 以获取最短回收停顿时间为目标
            - 并发收集，低停顿

    - 缺点

        - 对CPU资源非常敏感

            - CMS默认的回收线程数: （CPU数量+3）/4

        - 无法处理浮动垃圾

            - 产生大量空间碎片

- G1收集器（Garbage First）

    - “标记-整理”算法

        - 避免全区域的垃圾收集
        - 将整个Java堆（包括新生代、老年代）划分为多个大小固定的独立区域，并且跟踪这些区域里面的垃圾堆积程度，在后台维护一个优先列表，每次根据允许的收集时间，优先回收垃圾最多的区域
        - 区域划分、有优先级的区域回收，保证了G1收集器在有限的时间内可以获得最高的收集效率

### JVM性能调优

- jps、jinfo、jstack、jstat、jmap

## 网络

### TCP协议

- 三次握手

    - 目的

        - 为了确认双方的接收和发送能力是否正常，初始序列号，交换窗口大小以及 MSS 等信息

    - 过程

        - 客户端发送 SYN 报文，并进入 SYN_SENT 状态，等待服务器的确认

            - 客户端发送请求：SYN 1， 请求seq为x

                - 客户端的发送能力、服务端的接收能力是正常的

        - 服务器收到 SYN 报文，需要给客户端发送 ACK 确认报文，同时服务器也要向客户端发送一个 SYN 报文，所以也就是向客户端发送 SYN + ACK 报文，此时服务器进入 SYN_RCVD 状态

            - 服务端对客户端请求x进行响应：SYN1，ACK1，请求seq为y，应答为x+1

                - 服务端的发送能力是正常的。但是服务器并不能确认客户端的接收能力是否正常

            - 将对客户端的响应ACK和服务端的请求SYN合并为一次

        - 客户端收到 SYN + ACK 报文，向服务器发送确认包，客户端进入 ESTABLISHED 状态。待服务器收到客户端发送的 ACK 包也会进入 ESTABLISHED 状态，完成三次握手

            - 客户端对服务端请求y进行响应：SYN1，ACK1，请求seq为x+1，应答为y+1

                - 客户端的接收能力正常

    - 作用

- 四次挥手

    - 过程

        - 客户端发起 FIN 包（FIN = 1）,客户端进入 FIN_WAIT_1 状态。TCP 规定，即使 FIN 包不携带数据，也要消耗一个序号

            - 客户端不再发送数据，并向服务端提出关闭请求

        - 服务器端收到 FIN 包，发出确认包 ACK（ack = u + 1），并带上自己的序号 seq=v，服务器端进入了 CLOSE_WAIT 状态。这个时候客户端已经没有数据要发送了，不过服务器端有数据发送的话，客户端依然需要接收。客户端接收到服务器端发送的 ACK 后，进入了 FIN_WAIT_2 状态

            - 服务端确认关闭请求
            - 关闭等待(CLOSE_WAIT)

                - 等待服务器向客户端发送完数据再发起关闭请求

        - 服务器端数据发送完毕后，向客户端发送 FIN 包（seq=w ack=u+1），半连接状态下服务器可能又发送了一些数据，假设发送 seq 为 w。服务器此时进入了 LAST_ACK 状态

            - 服务端不再发送数据，并向客户端提出关闭请求

        - 客户端收到服务器的 FIN 包后，发出确认包（ACK=1，ack=w+1），此时客户端就进入了 TIME_WAIT 状态。注意此时 TCP 连接还没有释放，必须经过 2*MSL 后，才进入 CLOSED 状态

            - 客户端确认关闭请求
            - 超时等待(TIME_WAIT)

                - 等待服务端不发起新请求再进入关闭状态
                - 等待2MSL的原因

                    - MSL 指的是报文在网络中最大生存时间
                    - 在客户端发送对服务器端的 FIN 的确认包 ACK 后，这个 ACK 包是有可能不可达的，服务器端如果收不到 ACK 的话需要重新发送 FIN 包
                    - 客户端发送 ACK 后需要留出 2MSL 时间（ACK 到达服务器 + 服务器发送 FIN 重传包，一来一回）等待确认服务器端确实收到了 ACK 包
                    - 如果等待 2MSL 时间也没有收到服务器端的重传包 FIN，说明可以确认服务器已经收到客户端发送的 ACK

- 滑动窗口

    - 单次发送确认的缺点

        - 数据包的往返时间越长，通信的效率就越低

    - 窗口大小

        - 无需等待确认应答，而可以继续发送数据的最大值。

    - 实现

        - 操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

    - 发送方的滑动窗口

        - SND.WND：表示发送窗口的大小
        - SND.UNA：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号
        - SND.NXT：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号
        - 相对指针：SND.UNA 指针加上 SND.WND 大小的偏移量

    - 接收方的滑动窗口

        - RCV.WND：表示接收窗口的大小，它会通告给发送方
        - RCV.NXT：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号
        - 相对指针：RCV.NXT 指针加上 RCV.WND 的偏移量

- 拥塞控制

    - 避免「发送方」的数据填满整个网络
    - 拥塞窗口

        - 网络的拥塞程度动态变化的
        - 只要网络中没有出现拥塞，cwnd 就会增大
        - 但网络中出现了拥塞，cwnd 就减少

    - 拥塞判定

        - 只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了用拥塞

    - 拥塞控制算法

        - 慢启动

            - 当拥塞窗口小于慢启动阈值时会执行慢启动
            - 当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1

        - 拥塞避免

            - 当拥塞窗口大小超过慢启动阈值就会进入拥塞避免算法
            - 每当收到一个 ACK 时，cwnd 增加 1/cwnd

        - 拥塞发生

            - 超时重传

                - 当发送端发送数据，发生丢包时，则丢掉的包的ACK一直不会返回。此时发送端就一直等那个ACK返回，若超时，则重传该数据包
                - 慢启动门限变为拥塞窗口的一半

                    - 拥塞窗口重设为1

                - 重新从慢启动开始

            - 快速重传

                - 丢包时接收端重复发送丢包前的ACK，发送端每发送一个包过来，接收端就发相同的ACK回去，这个ACK是对丢包之前的确认。当接收端连续收到3个相同的ACK，它就知道发生丢包了，根据ACK序号就能重发丢的包
                - 拥塞窗口设为原来的一半

                    - 慢启动阈值等于拥塞窗口大小

                - 进入快速恢复算法

        - 快速恢复

- 粘包原因和解决方法

    - 原因

        - 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包
        - 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。
        - 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包
        - 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包

    - 解决方法

        - 发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了
        - 发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来
        - 可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开

### 常见网络服务分层

- OSI

    - 应用层

        - 网络服务与最终用户的一个接口。

            - HTTP FTP TFTP SMTP SNMP DNS TELNET HTTPS POP3 DHCP

    - 表示层

        - 数据的表示、安全、压缩

            - JPEG、ASCll、EBCDIC、加密格式

    - 会话层

        - 建立、管理、终止会话

            - 对应主机进程，指本地主机与远程主机正在进行的会话

    - 传输层

        - 定义传输数据的协议端口号，以及流控和差错校验

            - TCP UDP

    - 网络层

        - 进行逻辑地址寻址，实现不同网络之间的路径选择

            -  IP（IPV4 IPV6）

    - 数据链路层

        - 建立逻辑连接、进行硬件地址寻址、差错校验等功能

    - 物理层

        - 建立、维护、断开物理连接

- TCP/IP

    - 应用层、表示层、会话层合并到一起

### http协议

- 1.0、1.1、2.0的内容和区别

    - 1.0

        - 规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求

            - 连接无法复用

                - 对文件类大请求影响较大

            - head of line blocking

                - 导致健康的请求会被不健康的请求影响

    - 1.1

        - 支持持久连接（HTTP/1.1的默认模式使用带流水线的持久连接），在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟

    - 2.0

        - 多路复用

            - 多路复用允许同时通过单一的 HTTP/2 连接发起多重的请求-响应消息

        - 二进制分帧

            - 增加一个二进制分帧层，实现低延迟和高吞吐量

        - 首部压缩
        - 服务端推送

            - 服务器可以对客户端的一个请求发送多个响应

- https http区别

    - 超文本传输协议，是一个基于请求与响应，无状态的，应用层的协议，常基于TCP/IP协议传输数据，互联网上应用最为广泛的一种网络协议,所有的WWW文件都必须遵守这个标准。设计HTTP的初衷是为了提供一种发布和接收HTML页面的方法
    - HTTPS是一种通过计算机网络进行安全通信的传输协议，经由HTTP进行通信，利用SSL/TLS建立全信道，加密数据包。HTTPS使用的主要目的是提供对网站服务器的身份认证，同时保护交换数据的隐私与完整性。
    - https协议需要到CA申请证书，一般免费证书较少，因而需要一定费用
    - http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443
    - http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl/tls加密传输协议
    - http的连接很简单，是无状态的；HTTPS协议是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全

- 对称加密和非对称加密

    - 对称加密

        -  如DES算法，即一个主站与用户之间可以使用相同的密钥对传输内容进行加密

            -  对称加密密钥传输不安全

                - 使用对称加密来加密数据

    - 非对称加密

        -  如RSA加密算法，把密码革命性的分成公钥和私钥，由于两个密钥并不相同，所以称为非对称加密

            - 非对称加密加密速度慢

                - 使用非对称加密来传输对称加密的密钥

### URL到页面解析过程

-  域名解析

    - 查找浏览器内部缓存

        - 网络进程会先看看是否存在本地DNS缓存，如果有就直接返回资源给浏览器进程

    - 本地Host文件
    - 本地路由器的DNS缓存
    - 网络服务商中DNS服务器
    - 建立TCP连接，三次握手

        - 利用IP地址和服务器建立TCP连接，向服务器发送请求

- 服务器响应

    - 重定向

        - 响应行状态码为301（永久重定向）和302（临时），那么说明需要重定向到其他url。网络进程会从响应头中的Location字段里读取重定向的地址，并重新发起网络请求

    - 响应数据处理

        - 导航会通过请求头的Content-type字段判断响应体数据的类型。浏览器通过这个来决定如何显示响应体的内容
        - MVC

            - 用户的请求数据通过控制器交给模型来处理
            - 模型根据用户的请求数据，在数据库中查询，调用相应的数据返回给控制器
            - 控制器得到数据库返回数据后，交给视图模板填充形成页面的模板
            - 视图模板填充好后，把数据反馈给控制器
            - 控制器将数据反馈给浏览器

- 浏览器的接受数据和页面渲染

    - 根据浏览器的渲染机制对相应的数据进行渲染
    - 渲染后的数据，进行相应的页面呈现和脚步的交互

## redis

### zset有序集合对象

- 使用ziplist

    - 元素数量小于128个且所有member的长度都小于64字节

- ziplist

    - 使用紧挨在一起的压缩列表节点来保存，第一个节点保存member，第二个保存score。ziplist内的集合元素按score从小到大排序，score较小的排在表头位置

- skiplist

    - 是一个命名为zset的结构体，而一个zset结构同时包含一个字典和一个跳跃表。跳跃表按score从小到大保存所有集合元素。而字典则保存着从member到score的映射，这样就可以用O(1)的复杂度来查找member对应的score值。虽然同时使用两种结构，但它们会通过指针来共享相同元素的member和score，因此不会浪费额外的内存。

### 简单动态字符串sds

- 杜绝缓冲区溢出问题

    - 字符串拼接前先判断free是否足够，不足不会覆盖

- 减少字符串扩容时内存重新分配的次数

    - 进行空间预分配
    - 惰性空间释放

- 获取字符串长度的复杂度为O(1)

    - C语言不记录字符串长度

- 二进制安全

    - 能包含空字符，可以存储图片等非文本数据

### 列表

- quick list

    - 由ziplist组成的双向链表，链表中的每一个节点都以压缩列表ziplist的结构保存着数据，而ziplist有多个entry节点，保存着数据
    - quicklist宏观上是一个双向链表，因此，它具有一个双向链表的有点，进行插入或删除操作时非常方便，虽然复杂度为O(n)，但是不需要内存的复制，提高了效率，而且访问两端元素复杂度为O(1)
    - quicklist微观上是一片片entry节点，每一片entry节点内存连续且顺序存储，可以通过二分查找以 log2(n)log2(n) 的复杂度进行定位。

### 字典

- 渐进式哈希

    - 把拷贝节点数据的过程平摊到后续的操作中，而不是一次性拷贝（插入，查找，删除，修改时都会进行拷贝）
    - 步骤

        - 为ht[1]哈希表分配表空间.维持一个索引计数器变量rehashidx，初始为0
        - 在增删改查时，先查询ht[0]，如果查询到则会顺带将ht[0]哈希表中的所有键值对rehash到ht[1],同时索引计数器加一
        - 当所有键值对全部rehash到ht[1]时，则重新将索引计数器值为-1，表示rehash已完成

    - 避免集中式rehash带来的庞大计算量

- 哈希表
- 字典只使用哈希表ht[0]，只在rehash时使用ht[1]

### 内存淘汰策略

- noeviction:添加数据时，如果redis判断该操作会导致占用内存大小超过内存限制，就返回error，然后啥也不干
- allkeys-lru:添加数据时，如果redis判断该操作会导致占用内存大小超过内存限制，就会扫描所有的key，淘汰一些最近未使用的key
- volatile-lru:添加数据时，如果redis判断该操作会导致占用内存大小超过内存限制，扫描那些设置里过期时间的key，淘汰一些最近未使用的key
- allkeys-random:添加数据时，如果redis判断该操作会导致占用内存大小超过内存限制，就会扫描所有的key，随机淘汰一些key
- volatile-random:添加数据时，如果redis判断该操作会导致占用内存大小超过内存限制，扫描那些设置里过期时间的key，随机淘汰一些key
- volatile-ttl:添加数据时，如果redis判断该操作会导致占用内存大小超过内存限制，扫描那些设置里过期时间的key，淘汰一些即将过期的key
- volatile-lfu:添加数据时，如果redis判断该操作会导致占用内存大小超过内存限制，就会淘汰一些设置了过期时间的，并且最近最少使用的key
- allkeys-lfu:添加数据时，如果redis判断该操作会导致占用内存大小超过内存限制，就会扫描所有的key，淘汰一些最近最少使用的key
- 最近最久未使用LRU

    - 可用 new LinkedHashMap<Integer, Integer>(0, 0.75f, true)实现，false-按照插入顺序排序；true-按照访问顺序排序

- 最近最少使用LFU

    - 为每个key维护了一个计数器，每次key被访问的时候，计数器增大，计数器越大，则认为访问越频繁

### 缓存失效策略

- 定期删除

    - 定期删除是指Redis默认每隔 100ms 就 随机抽取 一些设置了过期时间的key，检测这些key是否过期，如果过期了就将其删除

- 惰性删除

    - 惰性删除不是去主动删除，而是在你要获取某个key 的时候，redis会先去检测一下这个key是否已经过期，如果没有过期则返回给你，如果已经过期了，那么redis会删除这个key，不会返回给你

### 缓存问题

- 缓存穿透

    - 缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义

        - 接口层增加校验
        - 将key-value对写为key-null，缓存有效时间可以设置短点

- 缓存雪崩

    - 缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库

        - 采用多级缓存，本地进程作为一级缓存，redis作为二级缓存，不同级别的缓存设置的超时时间不同，即使某级缓存过期了，也有其他级别缓存兜底
        - 缓存的过期时间用随机值，尽量让不同的key的过期时间不同
        - 可以把缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务。利用sentinel或cluster实现
        - 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中
        - 设置热点数据永远不过期。

- 缓存击穿

    - 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力

        - 设置热点数据永远不过期。
        - 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些 服务  不可用时候，进行熔断，失败快速返回机制
        - 布隆过滤器。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回
        - 加互斥锁

### 分布式锁

- 加锁
- 解锁
- 看门狗机制

    - 线程去获取锁，获取成功则执行lua脚本，保存数据到redis数据库。如果获取失败: 一直通过while循环尝试获取锁(可自定义等待时间，超时后返回失败)，获取成功后，执行lua脚本，保存数据到redis数据库。Redisson提供的分布式锁是支持锁自动续期的，也就是说，如果线程仍旧没有执行完，那么redisson会自动给redis中的目标key延长超时时间，这在Redisson中称之为 Watch Dog 机制
    - Redisson提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期，也就是说，如果一个拿到锁的线程一直没有完成逻辑，那么看门狗会帮助线程不断的延长锁超时时间，锁不会因为超时而被释放。
    - 默认情况下，看门狗的续期时间是30s，也可以通过修改Config.lockWatchdogTimeout来另行指定。另外Redisson 还提供了可以指定leaseTime参数的加锁方法来指定加锁的时间。超过这个时间后锁便自动解开了，不会延长锁的有效期

## kafka

### reblance机制

- Reblance是Kafka协调者把partition分配给Consumer-group下每个consumer实例的过程。rebalance规定了一个 Consumer Group 下的所有 consumer 如何达成一致，来分配订阅 Topic 的每个分区
- 触发条件

    - 组成员个数发生变化

        - consumer成员变更
        - consumer 加入群组或者离开群组的时候
        - consumer被检测为崩溃的时候

    - 订阅的 Topic 个数发生变化
    - 订阅 Topic 的分区数发生变化

- 过程

    - consumer通过fetch线程拉消息（单线程）
    - consumer通过心跳线程来与broker发送心跳。超时会认为挂掉
    - 每个consumer group在broker上都有一个coordnator来管理，消费者加入和退出

- 影响

    - 可能重复消费
    - 集群不稳定
    - 影响消费速度

- 措施

    - 业务需要不可避免

        - 业务需要增加分区
        - Topic的订阅增加或取消亦不可避免

    - 合理设置消费者参数

        - 未能及时发送心跳而Rebalance

            - session.timeout.ms  一次session的连接超时时间
            - heartbeat.interval.ms  心跳时间，一般为超时时间的1/3，Consumer在被判定为死亡之前，能够发送至少 3 轮的心跳请求

        - Consumer消费超时而Rebalance

            - max.poll.interval.ms  每隔多长时间去拉取消息
            - max.poll.records  一次从拉取出来的数据条数。
            - 尽可能在max.poll.interval.ms时间间隔内处理完max.poll.records条消息

### 如何做到有且仅消费一次

- 幂等producer

    - 保证发送单个分区的消息只会发送一次，不会出现重复消息

- 事务

    - 保证原子性地写入到多个分区，即写入到多个分区的消息要么全部成功，要么全部回滚流处理EOS：流处理本质上可看成是“读取-处理-写入”的管道。此EOS保证整个过程的操作是原子性

### Leo和hw

- HW

    - 高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。

- LEO

    - 标识当前日志文件中下一条待写入的消息的offset

- 当leader副本收到生产者的一条消息，LEO通常会自增1，而follower副本需要从leader副本fetch到数据后，才会增加它的LEO，最后leader副本会比较自己的LEO以及满足条件的follower副本上的LEO，选取两者中较小值作为新的HW，来更新自己的HW值

###  如何保证顺序消费

- 1个Topic（主题）只创建1个Partition(分区)，这样生产者的所有数据都发送到了一个Partition(分区)，保证了消息的消费顺序
- 生产者在发送消息的时候指定要发送到哪个Partition(分区)

### 如何保证消息不丢

- 首先对kafka进行限速， 其次启用重试机制，重试间隔时间设置长一些，最后Kafka设置acks=all，即需要相应的所有处于ISR的分区都确认收到该消息后，才算发送成功

### 如何保证消息不重复消费

- 消息可以使用唯一id标识
- 生产者（ack=all 代表至少成功发送一次)
- 消费者 （offset手动提交，业务逻辑成功处理后，提交offset）
- 落表（主键或者唯一索引的方式，避免重复数据）
- 业务逻辑处理（选择唯一主键存储到Redis或者mongdb中，先查询是否存在，若存在则不处理；若不存在，先插入Redis或Mongdb,再进行业务逻辑处理）

### 如何解决线上消息积压

- Kafka消费能力不足

    - 增加 topic 的 partition 的个数，同时提升消费者组的消费者数量，消费数 = 分区数

- 下游数据处理不及时

    - 提高每批次拉取的数量。批次拉取数量过少（拉取数据/处理时间 < 生产速度），使处理的数据小于生产的数据，也会造成数据积压

## 分布式事务

### 两种理论

- CAP定理

    - C：Consistency一致性
    - A：Availability可用性
    - P：Partition tolerance分区容错性
    - CA

        - 放弃分区容错性，加强一致性和可用性，其实就是传统的单机数据库的选择

    - AP

        - 放弃一致性（这里说的一致性是强一致性），追求分区容错性和可用性，这是很多分布式系统设计时的选择，例如很多NoSQL系统就是如此

    - CP

        - 放弃可用性，追求一致性和分区容错性，基本不会选择，网络问题会直接让整个系统不可用

- BASE理论

    - 基本可用

        - 指分布式系统在出现不可预知故障的时候，允许损失部分可用性。允许响应时间上的损失和系统功能上的损失

    - 软状态

        - 允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时

    - 最终一致性

        - 强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态

    - 柔性事务

        - 如果将实现了ACID特性的事务称为刚性事务的话，那么基于BASE事务要素的事务则称为柔性事务

### 三个协议

- 2PC二阶段提交

    - 确认服务正常、写提交事务日志

        - 在准备阶段中，协调者发起一个提议，分别问询各参与者是否接受

    - 提交事务日志到数据库

        - 在提交阶段，协调者根据参与者的反馈，提交或回滚事务，如果参与者全部同意则提交，只要有一个参与者不同意就中止

    - 问题

        - 同步阻塞问题

            - 所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态

        - 单点故障

            - 由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去

        - 数据不一致

            - 当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求

- 3PC三阶段提交

    - 引入超时机制

        - 在协调者和参与者中都引入超时机制

    - 在第一阶段和第二阶段中插入一个准备阶段
    - CanCommit

        - 确认服务正常

            - 协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应

    - PreCommit

        - 写提交事务日志

            - 协调者根据参与者的反应情况来决定是否可以执行事务的PreCommit操作。

                - 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令
                - 有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断

    - doCommit

        - 提交事务日志到数据库

            - 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求
            - 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源
            - 事务提交完之后，向协调者发送Ack响应。

                - 协调者接收到所有参与者的ack响应之后，完成事务。
                - 协调者没有接收到参与者发送的ACK响应那么就会执行中断事务

    - 问题

        - 整个事务过程是同步阻塞的，相比二阶段提交，使用了超时机制
        - 数据可能出现不一致

- TCC两阶段补偿

    - TRY阶段

        - 新增数据（本地事务），状态设为“未提交”。如果事务参与者全都返回成功，则执行Commit，否则Cancel

    - Commit阶段

        - 提交数据，将a新增的数据状态设为“已提交”，如果任意一方出现异常，则执行Cancel

    - Cancel阶段

        - 删除数据，将a新增的数据状态设为“已撤销”，如果撤销失败，则记录下来，人工处理

    - 问题

        - 实现复杂，业务复杂度高
        - 数据可能出现不一致

- Saga拆分事务+补偿机制

    - 事务阶段

        - Ti

            - 通过子事务直接添加/修改数据，多个Ti的执行

        - Ci

            - 针对Ti的补偿机制，多个Ci的执行

    - 执行策略

        - 回退

            - 如果有失败的子事务，则将成功了的子事务全部做补偿机制Ci

        - 重试

            - 如果有失败的子事务，则继续重试，重试N次也不成功，则人工干预

## spring

### 自动装配

- 自动配置真正实现是从classpath中搜寻所有的META-INF/spring.factories配置文件 ，并将其中对应的 org.springframework.boot.autoconfigure. 包下的配置项，通过反射实例化为对应标注了 @Configuration的JavaConfig形式的IOC容器配置类 ， 然后将这些都汇总成为一个实例并加载到IOC容器中
- SpringBoot在启动的时候从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值
- 将这些值作为自动配置类导入容器 ， 自动配置类就生效 ， 帮我们进行自动配置工作
- 整个J2EE的整体解决方案和自动配置都在springboot-autoconfigure的jar包中
- 它会给容器中导入非常多的自动配置类 （xxxAutoConfiguration）, 就是给容器中导入这个场景需要的所有组件 ， 并配置好这些组件
- 有了自动配置类 ， 免去了我们手动编写配置注入功能组件等的工作

### @SpringBootApplication 的原理

- @SpringBootConfiguration

    - Spring Boot的配置类

- @EnableAutoConfiguration

    - 开启自动配置功能
    - @Import({AutoConfigurationImportSelector.class})

        - 给容器导入组件
        - AutoConfigurationImportSelector

### bean 创建的详细过程

-

### 循环依赖

- 当bean A依赖于bean B,且bean B也依赖于bean A时，就发生了循环依赖
- 解决方法

    - 重新设计
    - 使用@Lazy
    - 使用Setter/Field注入
    - 使用@PostConstruct
    - 实现 ApplicationContextAware和InitializingBean

- spring如何解决？三级缓存

    - 一级缓存

        - 存储单例对象，Bean 已经实例化，初始化完成

    - 二级缓存

        - 存储 singletonObject，这个 Bean 实例化了，还没有初始化

    - 三级缓存

        - 存储 singletonFactory

    - 不使用二级缓存的原因

        - 只使用二级缓存的话，可以将aop的代理工作提前到 提前暴露实例的阶段执行； 也就是说所有的bean在创建过程中就先生成代理对象再初始化和其他工作； 但是这样的话，就和spring的aop的设计原则相驳，aop的实现需要与bean的正常生命周期的创建分离； 这样只有使用第三级缓存封装一个函数式接口对象到缓存中， 发生循环依赖时，触发代理类的生成才会与bean创建分离

### starter加载的原理

- spring-boot启动的时候会找到starter jar包中的resources/META-INF/spring.factories文件，根据spring.factories文件中的配置，找到需要自动配置的类
- 根据 spring.factories配置加载AutoConfigure类
- 根据 @Conditional 注解的条件，进行自动配置并将Bean注入Spring Context

### 事务传播机制

- 传播属性Propagation

    - PROPAGATION_REQUIRED

        - 支持当前事务，如果当前没有事务，则新建一个事务（默认）

    - PROPAGATION_SUPPORTS

        - 支持当前事务，如果当前没有事务，则以非事务方式执行

    - PROPAGATION_MANDATORY

        - 支持当前事务，如果当前没有事务，则抛出异常

    - PROPAGATION_REQUIRES_NEW

        - 新建事务，如果当前存在事务，把当前事务挂起

    - PROPAGATION_NOT_SUPPORTED

        -  以非事务方式执行操作，如果当前存在事务，就把当前事务挂起

    - PROPAGATION_NEVER

        -  以非事务方式执行，如果当前存在事务，则抛出异常

    - PROPAGATION_NESTED

        - Nested的事务和它的父事务是相依的，它的提交是要等和它的父事务一块提交的

- 隔离级别

    - ISOLATION_DEFAULT

        - 数据库默认的事务隔离级别。

    - ISOLATION_READ_UNCOMMITTED

        - 事务最低的隔离级别，它允许另外一个事务可以看到这个事务未提交的数据

    - ISOLATION_READ_COMMITTED

        - 保证一个事务修改的数据提交后才能被另外一个事务读取，其它事务不能读取该事务未提交的数据

    - ISOLATION_REPEATABLE_READ

        - 保证一个事务不能读取另一个事务未提交的数据，避免了“脏读取”和“不可重复读取”的情况，但是带来了更多的性能损失

    - ISOLATION_SERIALIZABLE

        - 这是最可靠的但是代价花费最高的事务隔离级别，事务被处理为顺序执行

### eureka

- 自我保护机制

    - 默认情况下，如果在一定时间内超过指定阈值的客户端节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障(比如网络故障或频繁的启动关闭客户端)，Eureka Server自动进入自我保护模式。不再剔除任何服务，当网络故障恢复后，该节点自动退出自我保护模式。
    - 激活条件

        - 在 1 分钟后，客户端实例续约的总数<期望每分钟收到客户端实例续约的总数

## 问题

### 代码简洁

- 可读性、复用性、拓展性

### 架构设计

- 高可用、高性能、高并发

### 场景设计

- 拼多多拼购库表结构和接口设计
- 微信扫码登录如何实现，细节

### 编程

- 手写最近最少未使用淘汰算法LRU
- 堆排序
- 多线程交替打印abc
- topk
- 词频统计
- 布隆过滤器
- 手写限流算法
- 手写线程池

